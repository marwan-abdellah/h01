{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad42837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_ids_to_txt_file(df, file_path):\n",
    "    \"\"\"\n",
    "    Save the IDs from the DataFrame to a text file, one per line.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing an 'id' column.\n",
    "        file_path (str): Path to the output text file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        for index, row in df.iterrows():\n",
    "            f.write(f\"{row['id']}\\n\")\n",
    "\n",
    "# Load the CSV file containing cell data\n",
    "df = pd.read_csv('data/h01.csv')\n",
    "\n",
    "# Filter for neurons using the 'data' column\n",
    "df_neurons = df[df['data'].str.contains('#neuron')]\n",
    "print(\"Neurons:\", len(df_neurons))\n",
    "save_ids_to_txt_file(df_neurons, 'neurons.ids')\n",
    "\n",
    "# Filter for pyramidal neurons\n",
    "df_pyramidal = df_neurons[df_neurons['data'].str.contains('#pyramidal ')]\n",
    "print(\"Pyramidals:\", len(df_pyramidal))\n",
    "save_ids_to_txt_file(df_pyramidal, 'pyramidal.ids')\n",
    "\n",
    "# Save pyramidal neuron IDs by cortical layer\n",
    "for i in [1, 2, 3, 4, 5, 6]:\n",
    "    df_pyramidal_layer = df_neurons[df_neurons['data'].str.contains(f'#L{i}')]\n",
    "    print(f\"Pyramidals: L{i}\", len(df_pyramidal_layer))\n",
    "    save_ids_to_txt_file(df_pyramidal_layer, f'pyramidal_L{i}.ids')\n",
    "\n",
    "# Filter for interneurons\n",
    "df_interneuron = df_neurons[df_neurons['data'].str.contains('#interneuron ')]\n",
    "print(\"Interneurons:\", len(df_interneuron))\n",
    "save_ids_to_txt_file(df_interneuron, 'interneurons.ids')\n",
    "\n",
    "# Save interneuron IDs by cortical layer\n",
    "for i in [1, 2, 3, 4, 5, 6]:\n",
    "    df_interneuron_layer = df_interneuron[df_interneuron['data'].str.contains(f'#L{i}')]\n",
    "    print(f\"Interneurons: L{i}\", len(df_interneuron_layer))\n",
    "    save_ids_to_txt_file(df_interneuron_layer, f'interneurons_L{i}.ids')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5784bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Tokens need to be acquired by hand. Please follow the following steps:\n",
      "                1) Go to: https://global.brain-wire-test.org//auth/api/v1/create_token to create a new token.\n",
      "                2) Log in with your Google credentials and copy the token shown afterward.\n",
      "                3a) Save it to your computer with: client.auth.save_token(token=\"PASTE_YOUR_TOKEN_HERE\")\n",
      "                or\n",
      "                3b) Set it for the current session only with client.auth.token = \"PASTE_YOUR_TOKEN_HERE\"\n",
      "                Note: If you need to save or load multiple tokens, please read the documentation for details.\n",
      "                Warning! Creating a new token by finishing step 2 will invalidate the previous token!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening in existing browser session.\n"
     ]
    }
   ],
   "source": [
    "import caveclient\n",
    "url = \"https://global.brain-wire-test.org/\"\n",
    "auth = caveclient.auth.AuthClient(server_address=url)\n",
    "auth.setup_token(make_new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6cf43d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_token = \"be1bde27490bb4f37580cc370ba9068a\"\n",
    "auth.save_token(token=auth_token, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is already there!\n",
      "8841fffdac923d4cee7b07fe82e11987\n"
     ]
    }
   ],
   "source": [
    "from caveclient import CAVEclient\n",
    "client = CAVEclient()\n",
    "try:\n",
    "    client.auth.save_token(token=auth_token)\n",
    "except :\n",
    "    print(\"Token is already there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cloudvolume\n",
    "\n",
    "def create_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def get_cave_client(dataset):\n",
    "    \"\"\"\n",
    "    Returns a CAVEclient for the given dataset.\n",
    "    \"\"\"\n",
    "    client = caveclient.CAVEclient(dataset, auth_token=auth_token)\n",
    "    print(client.info.get_datastack_info())\n",
    "    return client\n",
    "\n",
    "def get_cloud_volume(path):\n",
    "    \"\"\"\n",
    "    Returns a CloudVolume object for the given path.\n",
    "    \"\"\"\n",
    "    print(\"Getting the cloud volume\")\n",
    "    return cloudvolume.CloudVolume(path, use_https=True, progress=True)\n",
    "\n",
    "def load_ids_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Loads a list of IDs from a file (one per line).\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        ids = [l.strip('\\n') for l in f]\n",
    "    return ids\n",
    "\n",
    "def download_cell_from_cloud_volume(cloud_volume, cell_id, output_directory):    \n",
    "    \"\"\"\n",
    "    Downloads a mesh for a single cell_id from the cloud volume and saves as .obj.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mesh = cloud_volume.mesh.get(cell_id)[cell_id]\n",
    "        with open(f'{output_directory}/{cell_id}.obj', 'wb') as f:\n",
    "            f.write(mesh.to_obj())\n",
    "    except Exception as e:\n",
    "        print(f\"Error in downloading the cell {cell_id}\")\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def download_cells_from_cloud_volume(cloud_volume, cell_ids, output_directory):\n",
    "    \"\"\"\n",
    "    Downloads meshes for a list of cell_ids from the cloud volume.\n",
    "    \"\"\"\n",
    "    for cell_id in cell_ids:\n",
    "        if int(cell_id) > 0:\n",
    "            print(f'Loading [{cell_id}]')\n",
    "            download_cell_from_cloud_volume(cloud_volume, int(cell_id), output_directory)\n",
    "\n",
    "def download_cells_from_cloud_volume_parallel(cloud_volume, cell_ids, output_directory, n_cores=8):\n",
    "    \"\"\"\n",
    "    Downloads meshes for a list of cell_ids in parallel.\n",
    "    \"\"\"\n",
    "    from joblib import Parallel, delayed\n",
    "    commands = [[int(i), output_directory] for i in cell_ids]\n",
    "    Parallel(n_jobs=int(n_cores))(delayed(download_cell_from_cloud_volume)(\n",
    "        cloud_volume, i[0], i[1]) for i in commands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e6545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_file = \"/scratch/h01-data/ids/pyramidal_L5.ids\"\n",
    "output_directory = \"/hdd1/data/h01/pyramidal_L5\"\n",
    "\n",
    "ids = load_ids_from_file(ids_file)\n",
    "print(\"Number of ids: \", len(ids))\n",
    "\n",
    "# Create the output directory\n",
    "create_dir(output_directory)\n",
    "\n",
    "# Craete the cloud volume\n",
    "cloud_volume_path = \"precomputed://gs://h01-release/data/20210601/c3\"\n",
    "cloud_volume = get_cloud_volume(cloud_volume_path)\n",
    "\n",
    "# Download the cells from the cloud volume\n",
    "download_cells_from_cloud_volume_parallel(cloud_volume, ids, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
